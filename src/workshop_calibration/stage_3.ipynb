{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7580110",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Step 0 : Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.io import arff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import brier_score_loss, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import calibration as cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572c8228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 : Data loading\n",
    "\n",
    "random_state = 6\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", None)\n",
    "\n",
    "data = arff.___(\"../../data/dataset_stage_3.arff\")  # TODO\n",
    "df = pd.DataFrame(data[0])\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9eb90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 : Data Preparation\n",
    "X = df.___(include=[\"number\"])  # TODO\n",
    "\n",
    "label_cols = [\n",
    "    \"25400\",\n",
    "    \"29600\",\n",
    "    \"30400\",\n",
    "    \"33400\",\n",
    "    \"17300\",\n",
    "    \"19400\",\n",
    "    \"34500\",\n",
    "    \"38100\",\n",
    "    \"49700\",\n",
    "    \"50390\",\n",
    "    \"55800\",\n",
    "    \"57500\",\n",
    "    \"59300\",\n",
    "    \"37880\",\n",
    "]\n",
    "y = df[___].astype(___)  # TODO\n",
    "\n",
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349052ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 : Data Splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=___,  # TODO\n",
    "    shuffle=False,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "X_proper_train, X_cal, y_proper_train, y_cal = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=___,  # TODO\n",
    "    shuffle=False,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "print(f\"\\n X_train :\\n{X_train.head()}\")\n",
    "print(f\"shape : {X_train.shape}\")\n",
    "print(f\"\\n y_train :\\n{y_train.head()}\")\n",
    "print(f\"shape : {y_train.shape}\")\n",
    "print(f\"\\n X_test :\\n{X_test.head()}\")\n",
    "print(f\"shape : {X_test.shape}\")\n",
    "print(f\"\\n y_test :\\n{y_test.head()}\")\n",
    "print(f\"shape : {y_test.shape}\")\n",
    "print(f\"\\n X_proper_train :\\n{X_proper_train.head()}\")\n",
    "print(f\"shape : {X_proper_train.shape}\")\n",
    "print(f\"\\n y_proper_train :\\n{y_proper_train.head()}\")\n",
    "print(f\"shape : {y_proper_train.shape}\")\n",
    "print(f\"\\n X_cal :\\n{X_cal.head()}\")\n",
    "print(f\"shape : {X_cal.shape}\")\n",
    "print(f\"\\n y_cal :\\n{y_cal.head()}\")\n",
    "print(f\"shape : {y_cal.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1537660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 : Multi-output classifier non calibrated\n",
    "base_clf = ___(random_state=random_state)  # TODO\n",
    "multi_clf = MultiOutputClassifier(___)  # TODO\n",
    "multi_clf.fit(___, ___)  # TODO\n",
    "pred_probs_uncalibrated = multi_clf.predict_proba(___)  # TODO\n",
    "pred_y_uncalibrated = multi_clf.predict(___)  # TODO\n",
    "\n",
    "print(f\"\\n pred_probs_uncalibrated :\\n{pred_probs_uncalibrated}\")\n",
    "print(f\"\\n pred_y_uncalibrated :\\n{pred_y_uncalibrated}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0587419b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 : Model calibration\n",
    "calibrated_clfs = []\n",
    "pred_probs_calibrated = []\n",
    "pred_y_calibrated = []\n",
    "for i in range(y.shape[1]):\n",
    "    clf = CalibratedClassifierCV(base_clf, method=\"___\", cv=___)  # TODO\n",
    "    clf.fit(___, ___.iloc[:, i])  # TODO\n",
    "    calibrated_clfs.append(___)  # TODO\n",
    "    pred_probs_calibrated.append(clf.predict_proba(___))  # TODO\n",
    "    pred_y_calibrated.append(clf.predict(___))  # TODO\n",
    "\n",
    "# Conversion to numpy matrix\n",
    "pred_probs_uncalibrated_matrix = np.vstack([p[:, 1] for p in ___]).T  # TODO\n",
    "pred_probs_calibrated_matrix = np.vstack([p[:, 1] for p in ___]).T  # TODO\n",
    "\n",
    "pred_y_uncalibrated_matrix = np.array(___)  # TODO\n",
    "pred_y_calibrated_matrix = np.array(___).T  # TODO\n",
    "\n",
    "print(f\"pred_probs_uncalibrated_matrix:\\n{pred_probs_uncalibrated_matrix}\")\n",
    "print(f\"shape: {pd.DataFrame(pred_probs_uncalibrated_matrix).shape}\")\n",
    "print(f\"pred_probs_calibrated_matrix:\\n{pred_probs_calibrated_matrix}\")\n",
    "print(f\"shape: {pd.DataFrame(pred_probs_calibrated_matrix).shape}\")\n",
    "print(f\"pred_y_uncalibrated_matrix:\\n{pred_y_uncalibrated_matrix}\")\n",
    "print(f\"shape: {pd.DataFrame(pred_y_uncalibrated_matrix).shape}\")\n",
    "print(f\"pred_y_calibrated_matrix:\\n{pred_y_calibrated_matrix}\")\n",
    "print(f\"shape: {pd.DataFrame(pred_y_calibrated_matrix).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4ad2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6 : Compute metrics\n",
    "\n",
    "brier_scores_uncalibrated = [\n",
    "    brier_score_loss(___.iloc[:, i], ___[:, i])  # TODO\n",
    "    for i in range(y_test.shape[1])\n",
    "]\n",
    "brier_scores_calibrated = [\n",
    "    brier_score_loss(___.iloc[:, i], ___[:, i])  # TODO\n",
    "    for i in range(y_test.shape[1])\n",
    "]\n",
    "\n",
    "accuracy_scores_uncalibrated = [\n",
    "    accuracy_score(y_test.iloc[:, i], ___[:, i])  # TODO\n",
    "    for i in range(y_test.shape[1])\n",
    "]\n",
    "accuracy_scores_calibrated = [\n",
    "    accuracy_score(y_test.iloc[:, i], ___[:, i])  # TODO\n",
    "    for i in range(y_test.shape[1])\n",
    "]\n",
    "\n",
    "ece_scores_uncalibrated = [\n",
    "    cal.get_calibration_error(___[:, i], y_test.iloc[:, i])  # TODO\n",
    "    for i in range(___.shape[1])  # TODO\n",
    "]\n",
    "ece_scores_calibrated = [\n",
    "    cal.get_calibration_error(___[:, i], y_test.iloc[:, i])  # TODO\n",
    "    for i in range(___.shape[1])  # TODO\n",
    "]\n",
    "\n",
    "# Summary in a DataFrame\n",
    "brier_score_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Label\": [f\"label_{i}\" for i in range(y.shape[1])],\n",
    "        \"Brier Uncalibrated\": brier_scores_uncalibrated,\n",
    "        \"Brier Calibrated\": brier_scores_calibrated,\n",
    "    }\n",
    ")\n",
    "\n",
    "accuracy_score_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Label\": [f\"label_{i}\" for i in range(y.shape[1])],\n",
    "        \"Accuracy Uncalibrated\": accuracy_scores_uncalibrated,\n",
    "        \"Accuracy Calibrated\": accuracy_scores_calibrated,\n",
    "    }\n",
    ")\n",
    "\n",
    "ece_score_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Label\": [f\"label_{i}\" for i in range(y.shape[1])],\n",
    "        \"ECE Uncalibrated\": ece_scores_uncalibrated,\n",
    "        \"ECE Calibrated\": ece_scores_calibrated,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc621b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7 : Visualisation\n",
    "\n",
    "# Plot Accuracy per label before and after calibration\n",
    "plt.figure(figsize=(10, 5))\n",
    "accuracy_long = accuracy_score_df.melt(\n",
    "    id_vars=\"Label\", var_name=\"Type\", value_name=\"Accuracy\"\n",
    ")\n",
    "sns.barplot(data=accuracy_long, x=\"Label\", y=\"Accuracy\", hue=\"Type\")\n",
    "plt.title(\"Accuracy per Label - Before and After Calibration\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot Brier Score per label before and after calibration\n",
    "plt.figure(figsize=(10, 5))\n",
    "brier_long = brier_score_df.melt(\n",
    "    id_vars=\"Label\", var_name=\"Type\", value_name=\"Brier Score\"\n",
    ")\n",
    "sns.barplot(data=brier_long, x=\"Label\", y=\"Brier Score\", hue=\"Type\")\n",
    "plt.title(\"Brier Score per Label - Before and After Calibration\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot ECE per label before and after calibration\n",
    "plt.figure(figsize=(10, 5))\n",
    "ece_long = ece_score_df.melt(id_vars=\"Label\", var_name=\"Type\", value_name=\"ECE\")\n",
    "sns.barplot(data=ece_long, x=\"Label\", y=\"ECE\", hue=\"Type\")\n",
    "plt.title(\"Expected Calibration Error (ECE) per Label - Before and After Calibration\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3186e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
