{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ed6f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0 : Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.metrics import brier_score_loss, log_loss, f1_score\n",
    "from venn_abers import VennAbersCalibrator\n",
    "import xgboost as xgb\n",
    "import calibration as cal\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "from scipy.io import arff\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de0ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Loading\n",
    "print(\"Loading the dataset\")\n",
    "\n",
    "random_state = 28\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", None)\n",
    "\n",
    "data = ___  # TODO\n",
    "df = pd.DataFrame(data[0])\n",
    "\n",
    "print(___)  # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76638095",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2 : Balancing the classes by oversampling\n",
    "majority = df[df.label == ___]  # TODO\n",
    "minority = df[df.label == ___]  # TODO\n",
    "minority_upsampled = ___  # TODO\n",
    "\n",
    "df = ___  # TODO\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79294e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 : Feature Preparation\n",
    "X = ___  # TODO\n",
    "y = ___  # TODO\n",
    "print(X.head(10))\n",
    "print(pd.DataFrame(y, columns=[\"label\"]).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e765872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 : Feature Scaling\n",
    "scaler = ___  # TODO\n",
    "X = ___  # TODO\n",
    "print(pd.DataFrame(X).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3724ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 : Data Splitting for Training and Testing\n",
    "X_train, X_test, y_train, y_test = ___  # TODO\n",
    "\n",
    "print(pd.DataFrame(X_train).head(5))\n",
    "print(pd.Series(y_train).head(5))\n",
    "print(pd.DataFrame(X_test).head(5))\n",
    "print(pd.Series(y_test).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292e8675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6 : Data Splitting for Proper Training and Calibration\n",
    "X_proper_train, X_cal, y_proper_train, y_cal = ___  # TODO\n",
    "\n",
    "print(pd.DataFrame(X_proper_train).head(5))\n",
    "print(pd.Series(y_proper_train).head(5))\n",
    "print(pd.DataFrame(X_cal).head(5))\n",
    "print(pd.Series(y_cal).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2041dc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7 : Model Definition\n",
    "print(\"Models to test\")\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        max_iter=5000,\n",
    "        random_state=random_state,\n",
    "    ),\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        n_estimators=10,\n",
    "        random_state=random_state,\n",
    "    ),\n",
    "    \"XGBoost\": xgb.XGBClassifier(\n",
    "        tree_method=\"hist\",\n",
    "        random_state=random_state,\n",
    "    ),\n",
    "}\n",
    "results = {}\n",
    "\n",
    "for name_model in models.keys():\n",
    "    print(f\"- {name_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d34bf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8 : Example of model training\n",
    "print(\"Example of model training and evaluation\")\n",
    "model_example = ___  # TODO\n",
    "\n",
    "probs_example = ___  # TODO\n",
    "preds_example = ___  # TODO\n",
    "\n",
    "print(probs_example[:5])\n",
    "print(preds_example[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb541c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9 : Example of model evaluation\n",
    "acc_example = ___  # TODO\n",
    "brier_example = ___  # TODO\n",
    "logloss_example = ___  # TODO\n",
    "ece_example = ___  # TODO\n",
    "\n",
    "print(f\"Score Accuracy: {acc_example:.3f}\")\n",
    "print(f\"Brier Score: {brier_example:.3f}\")\n",
    "print(f\"Log Loss: {logloss_example:.3f}\")\n",
    "print(f\"Expected Calibration Error: {ece_example:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d8fd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10 : Model Evaluation\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n Entraînement du modèle : {name}\")\n",
    "    model.fit(X_train, y_train)\n",
    "    probs = model.predict_proba(X_test)[:, 1]\n",
    "    acc = f1_score(y_test, model.predict(X_test))\n",
    "    brier = brier_score_loss(y_test, probs)\n",
    "    logloss = log_loss(y_test, probs)\n",
    "    ece = cal.get_calibration_error(probs, y_test)\n",
    "    print(f\"Score Accuracy: {acc:.3f}\")\n",
    "    print(f\"Brier Score: {brier:.3f}\")\n",
    "    print(f\"Log Loss: {logloss:.3f}\")\n",
    "    print(f\"Expected Calibration Error: {ece:.3f}\")\n",
    "    results[name] = {\n",
    "        \"model\": model,\n",
    "        \"accuracy\": acc,\n",
    "        \"probs\": probs,\n",
    "        \"brier\": brier,\n",
    "        \"logloss\": logloss,\n",
    "        \"ece\": ece,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56996426",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_example.fit(X_proper_train, y_proper_train)\n",
    "\n",
    "# Step 11 : Example of model calibration : Sigmoid and Isotonic\n",
    "for method in [___]:  # TODO\n",
    "    print(f\"\\nCalibrating LogisticRegression with {method} method\")\n",
    "    # Wrap with CalibratedClassifierCV using the chosen method\n",
    "    calibrated_model = ___  # TODO\n",
    "\n",
    "    # Predict probabilities and classes on the test set\n",
    "    probs_cal = ___  # TODO\n",
    "    preds_cal = ___  # TODO\n",
    "    print(f\"Probs calibration: {probs_cal[:5]}\")\n",
    "    print(f\"Preds calibration: {preds_cal[:5]}\")\n",
    "\n",
    "    # Evaluate\n",
    "    acc_cal = ___  # TODO\n",
    "    brier_cal = ___  # TODO\n",
    "    logloss_cal = ___  # TODO\n",
    "    ece_cal = ___  # TODO\n",
    "    print(f\"Score Accuracy: {acc_cal:.3f}\")\n",
    "    print(f\"Brier Score: {brier_cal:.3f}\")\n",
    "    print(f\"Log Loss: {logloss_cal:.3f}\")\n",
    "    print(f\"Expected Calibration Error: {ece_cal:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5cf709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 12 : Example of model calibration : Venn-ABERS (part 1 : calibration)\n",
    "print(\"\\nCalibrating LogisticRegression with Venn-ABERS method\")\n",
    "# Fit the model on the proper training set\n",
    "___  # TODO\n",
    "# Get predicted probabilities for calibration and test sets\n",
    "p_cal = ___  # TODO\n",
    "p_test = ___  # TODO\n",
    "# Calibrate and predict with VennAbersCalibrator\n",
    "va = VennAbersCalibrator()\n",
    "probs_va = ___  # TODO\n",
    "preds_va = ___  # TODO\n",
    "print(f\"Probs calibration: {probs_va[:5]}\")\n",
    "print(f\"Preds calibration: {preds_va[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e4c842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 13 : Example of model calibration : Venn-ABERS (part 2 : evaluation)\n",
    "acc_va = ___  # TODO\n",
    "brier_va = brier_score_loss(___, ___)  # TODO\n",
    "logloss_va = log_loss(___, ___)  # TODO\n",
    "ece_va = cal.get_calibration_error(___, ___)  # TODO\n",
    "print(f\"Score Accuracy: {acc_va:.3f}\")\n",
    "print(f\"Brier Score: {brier_va:.3f}\")\n",
    "print(f\"Log Loss: {logloss_va:.3f}\")\n",
    "print(f\"Expected Calibration Error: {ece_va:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db590388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14 : Model Calibration\n",
    "def calibration():\n",
    "    for name in models.keys():\n",
    "        for method in [\"sigmoid\", \"isotonic\"]:\n",
    "            print(f\"\\n Calibration de {name} avec méthode {method}\")\n",
    "            base_model = models[name].fit(X_proper_train, y_proper_train)\n",
    "            calibrated_model = CalibratedClassifierCV(\n",
    "                estimator=base_model, method=method, cv=\"prefit\"\n",
    "            )\n",
    "            calibrated_model.fit(X_cal, y_cal)\n",
    "            probs = calibrated_model.predict_proba(X_test)[:, 1]\n",
    "            y_pred = calibrated_model.predict(X_test)\n",
    "            acc = f1_score(y_test, y_pred)\n",
    "            brier = brier_score_loss(y_test, probs)\n",
    "            logloss = log_loss(y_test, probs)\n",
    "            ece = cal.get_calibration_error(probs, y_test)\n",
    "            print(f\"Score Accuracy: {acc:.3f}\")\n",
    "            print(f\"Brier Score: {brier:.3f}\")\n",
    "            print(f\"Log Loss: {logloss:.3f}\")\n",
    "            print(f\"Expected Calibration Error: {ece:.3f}\")\n",
    "            name_method = f\"{name} + {method}\"\n",
    "            results[name_method] = {\n",
    "                \"probs\": probs,\n",
    "                \"accuracy\": acc,\n",
    "                \"brier\": brier,\n",
    "                \"logloss\": logloss,\n",
    "                \"ece\": ece,\n",
    "            }\n",
    "        print(f\"\\n Calibration de {name} avec méthode Venn-ABERS\")\n",
    "        base_model = models[name].fit(X_proper_train, y_proper_train)\n",
    "        p_cal = base_model.predict_proba(X_cal)\n",
    "        p_test = base_model.predict_proba(X_test)\n",
    "        va = VennAbersCalibrator()\n",
    "        probs = va.predict_proba(p_cal=p_cal, y_cal=np.array(y_cal), p_test=p_test)[\n",
    "            :, 1\n",
    "        ]\n",
    "        y_pred = va.predict(p_cal=p_cal, y_cal=np.array(y_cal), p_test=p_test)[:, 1]\n",
    "        acc = f1_score(y_test, y_pred)\n",
    "        brier = brier_score_loss(y_test, probs)\n",
    "        logloss = log_loss(y_test, probs)\n",
    "        ece = cal.get_calibration_error(probs, y_test)\n",
    "        print(f\"Score Accuracy: {acc:.3f}\")\n",
    "        print(f\"Brier Score: {brier:.3f}\")\n",
    "        print(f\"Log Loss: {logloss:.3f}\")\n",
    "        print(f\"Expected Calibration Error: {ece:.3f}\")\n",
    "        name_method = f\"{name} + Venn-ABERS\"\n",
    "        results[name_method] = {\n",
    "            \"probs\": probs,\n",
    "            \"accuracy\": acc,\n",
    "            \"brier\": brier,\n",
    "            \"logloss\": logloss,\n",
    "            \"ece\": ece,\n",
    "        }\n",
    "    return\n",
    "\n",
    "\n",
    "calibration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5680c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 15: Plot Results\n",
    "def plot():\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for name in [\n",
    "        \"Random Forest\",\n",
    "        \"Random Forest + sigmoid\",\n",
    "        \"Random Forest + isotonic\",\n",
    "        \"Random Forest + Venn-ABERS\",\n",
    "    ]:\n",
    "        res = results[name]\n",
    "        prob_true, prob_pred = calibration_curve(y_test, res[\"probs\"], n_bins=10)\n",
    "        plt.plot(prob_pred, prob_true, marker=\"o\", label=name)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "    plt.xlabel(\"Probabilité prédite\")\n",
    "    plt.ylabel(\"Fréquence observée\")\n",
    "    plt.title(\"Courbes de calibration\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for name in [\n",
    "        \"XGBoost\",\n",
    "        \"XGBoost + sigmoid\",\n",
    "        \"XGBoost + isotonic\",\n",
    "        \"XGBoost + Venn-ABERS\",\n",
    "    ]:\n",
    "        res = results[name]\n",
    "        prob_true, prob_pred = calibration_curve(y_test, res[\"probs\"], n_bins=10)\n",
    "        plt.plot(prob_pred, prob_true, marker=\"o\", label=name)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "    plt.xlabel(\"Probabilité prédite\")\n",
    "    plt.ylabel(\"Fréquence observée\")\n",
    "    plt.title(\"Courbes de calibration\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    score_df = pd.DataFrame.from_dict(\n",
    "        {\n",
    "            name: {\n",
    "                \"Accuracy\": res[\"accuracy\"],\n",
    "                \"Brier Score\": res[\"brier\"],\n",
    "                \"Log Loss\": res[\"logloss\"],\n",
    "                \"ECE\": res[\"ece\"],\n",
    "            }\n",
    "            for name, res in results.items()\n",
    "        },\n",
    "        orient=\"index\",\n",
    "    ).sort_index()\n",
    "\n",
    "    pd.set_option(\"display.max_rows\", None)\n",
    "    pd.set_option(\"display.width\", 0)\n",
    "\n",
    "    return score_df\n",
    "\n",
    "\n",
    "plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fe0898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 16 : Run metrics function\n",
    "def run_metrics(clf, X_test, y_test, results, probs=None, preds=None, va=False):\n",
    "    if probs is None and preds is None:\n",
    "        probs = clf.predict_proba(X_test)[:, 1]\n",
    "        preds = clf.predict(X_test)\n",
    "    if va:\n",
    "        probs = clf.predict_proba(X_test)[:, 1]\n",
    "        preds = clf.predict(X_test)[:, 1]\n",
    "    acc = f1_score(y_test, preds)\n",
    "    brier = brier_score_loss(y_test, probs)\n",
    "    logloss = log_loss(y_test, probs)\n",
    "    ece = cal.get_calibration_error(probs, y_test)\n",
    "    results[\"accuracy\"].append(acc)\n",
    "    results[\"brier\"].append(brier)\n",
    "    results[\"log loss\"].append(logloss)\n",
    "    results[\"ece\"].append(ece)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e295478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 17 : Model Comparison\n",
    "def compare_methods():\n",
    "    # Prepare results storage\n",
    "    metrics = [\"accuracy\", \"brier\", \"log loss\", \"ece\"]\n",
    "    methods = [\n",
    "        \"Uncalibrated\",\n",
    "        \"Isotonic\",\n",
    "        \"Isotonic prefit\",\n",
    "        \"Sigmoid\",\n",
    "        \"Sigmoid prefit\",\n",
    "        \"Prefit Venn-Abers\",\n",
    "        \"IVAP\",\n",
    "        \"CVAP\",\n",
    "    ]\n",
    "    results = {m: [] for m in metrics}\n",
    "\n",
    "    # Uncalibrated\n",
    "    clf = ___  # TODO\n",
    "    run_metrics(___)  # TODO\n",
    "\n",
    "    # Isotonic (cv=5)\n",
    "    iso = ___  # TODO\n",
    "    run_metrics(___)  # TODO\n",
    "\n",
    "    # Isotonic prefit\n",
    "    clf = GaussianNB()  # TODO\n",
    "    iso_prefit = ___  # TODO\n",
    "    run_metrics(___)  # TODO\n",
    "\n",
    "    # Sigmoid (cv=5)\n",
    "    sig = ___  # TODO\n",
    "    run_metrics(___)  # TODO\n",
    "\n",
    "    # Sigmoid prefit\n",
    "    clf = ___  # TODO\n",
    "    sig_prefit = ___  # TODO\n",
    "    run_metrics(___)  # TODO\n",
    "\n",
    "    # Prefit\n",
    "    clf = ___  # TODO\n",
    "    p_cal = ___  # TODO\n",
    "    p_test = ___  # TODO\n",
    "    va = ___  # TODO\n",
    "    va_prefit_prob = ___  # TODO\n",
    "    y_pred = ___  # TODO\n",
    "    run_metrics(___)  # TODO\n",
    "\n",
    "    # IVAP\n",
    "    va = ___  # TODO\n",
    "    run_metrics(___)  # TODO\n",
    "\n",
    "    # CVAP\n",
    "    va = ___  # TODO\n",
    "    run_metrics(___)  # TODO\n",
    "\n",
    "    print(\n",
    "        \"Summary of the results for the different calibration methods (base model: GaussianNB):\"\n",
    "    )\n",
    "    df_loss = pd.DataFrame(results, index=methods).T.round(3)\n",
    "    return df_loss\n",
    "\n",
    "\n",
    "compare_methods()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea4f20a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
